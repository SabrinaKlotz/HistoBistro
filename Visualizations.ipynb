{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe09984",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve, average_precision_score, confusion_matrix\n",
    "import yaml\n",
    "from options import Options\n",
    "from visualizations.receiver_operator_curve import plot_roc_curves_, plot_roc_curve, plot_roc_curves\n",
    "from visualizations.precision_recall_curve import plot_precision_recall_curve, plot_precision_recall_curves, plot_precision_recall_curves_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff93680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "\n",
    "parser = Options()\n",
    "args = parser.parser.parse_args('')  \n",
    "\n",
    "# Load the configuration from the YAML file\n",
    "with open(args.config_file, 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "# Update the configuration with the values from the argument parser\n",
    "for arg_name, arg_value in vars(args).items():\n",
    "    if arg_value is not None and arg_name != 'config_file':\n",
    "        config[arg_name]['value'] = getattr(args, arg_name)\n",
    "\n",
    "# Create a flat config file without descriptions\n",
    "config = {k: v['value'] for k, v in config.items()}\n",
    "\n",
    "print('\\n--- load options ---')\n",
    "for name, value in sorted(config.items()):\n",
    "    print(f'{name}: {str(value)}')\n",
    "\n",
    "cfg = argparse.Namespace(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfb3873",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.name = 'multi-all-same'\n",
    "cfg.cohorts = ['DACHS', 'QUASAR', 'RAINBOW', 'TCGA']\n",
    "cfg.norm = 'histaugan'\n",
    "cfg.target = 'isMSIH'\n",
    "\n",
    "cfg.logging_name = f'{cfg.name}_{cfg.model}_{\"-\".join(cfg.cohorts)}_{cfg.norm}_{cfg.target}'\n",
    "base_path = Path(cfg.save_dir) / cfg.logging_name\n",
    "result_path = base_path / 'results'\n",
    "\n",
    "test_cohorts = 'YCR-BCIP-resections'\n",
    "csv_paths = result_path.glob(f'fold*/outputs_{test_cohorts}.csv')\n",
    "pred_csvs = list(csv_paths)\n",
    "\n",
    "# log_name = 'Rainbow-Quasar-Dachs-TCGA'\n",
    "# log_name = 'stad_epo8_again_BERN-STAD-LEEDS-STAD-TCGA-STAD-TUM-STAD' \n",
    "# log_name = 'ctranspath_8epo_vit-cls_rand867_Dachs-Quasar-Rainbow-TCGA_macenko' # model for MSI-H\n",
    "# log_name = 'ctranspath_8epo_vit-cls_Dachs-Quasar-Rainbow-TCGA_macenko'  # model for BRAF and KRAS\n",
    "# log_name = 'histaugan_vit-cls_Dachs-Quasar-Rainbow-TCGA_histaugan' # histaugan model for MSI-H\n",
    "# log_name = 'histaugan_rand867_vit-cls_Dachs-Quasar-Rainbow-TCGA_histaugan' # histaugan model for MSI-H\n",
    "# log_name = 'raw_rand867_vit-cls_Dachs-Quasar-Rainbow-TCGA_raw' # raw model for MSI-H\n",
    "# csv_dir = Path('/lustre/groups/peng/workspace/sophia.wagner/logs/bcos/outputs')\n",
    "# log_name = '_bcos_TCGA_raw' # raw model for MSI-H\n",
    "\n",
    "# log_name = 'ctranspath_epo32_Dachs-Quasar-Rainbow_macenko'\n",
    "# log_name = 'ctranspath_epo8_vit-cls_Dachs_macenko' # model for age < 50\n",
    "# log_name = 'ctranspath_epo8_vit-cls_Quasar_macenko' # model for age < 50\n",
    "# eval_name = 'Yorkshire-resections'\n",
    "# eval_name_label = 'YCR-BCIP'\n",
    "# eval_name = 'Yorkshire-biopsies'\n",
    "# eval_name_label = 'YCR-BCIP-biopsies'\n",
    "# eval_name = 'Quasar'\n",
    "# eval_name = 'Dachs'\n",
    "# eval_name = 'Belfast'\n",
    "# eval_name_label = 'Epi700'\n",
    "# eval_name = 'KIEL-STAD'\n",
    "# target_label = 'isMSIH'\n",
    "# target_label_name = 'MSI-H'\n",
    "# target_label = 'braf'\n",
    "# target_label_name = 'BRAF'\n",
    "# target_label = 'kras'\n",
    "# target_label_name = 'KRAS'\n",
    "# csv_paths = csv_dir.glob(f'outputs_{log_name}_{target_label}_fold*_eval_{eval_name}.csv')\n",
    "# csv_paths = csv_dir.glob('outputs_Rainbow-Quasar-Dachs-TCGA-Munich-MECC-Duessel_isMSIH_fold*_eval_Yorkshire_resections.csv')\n",
    "# output_path = Path('/home/haicu/sophia.wagner/projects/genetic_alteration_prediction/figures/histaugan') \n",
    "# pred_csvs = list(csv_paths)\n",
    "true_label=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ce69b4",
   "metadata": {},
   "source": [
    "# Plot ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0208e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dfs = [pd.read_csv(p, dtype=str) for p in pred_csvs]\n",
    "\n",
    "y_trues = [df[\"ground_truth\"] == f'{true_label:.1f}' for df in pred_dfs]\n",
    "y_preds = [pd.to_numeric(df[f'logits']) for df in pred_dfs]\n",
    "title = f'{cfg.target} = {true_label}'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "if len(pred_dfs) == 1:\n",
    "    plot_roc_curve(ax, y_trues[0], y_preds[0], title=title)\n",
    "else:\n",
    "    plot_roc_curves(ax, y_trues, y_preds, title=title)\n",
    "#     fig.savefig(Path(output_path)/f'roc-{target_label}={true_label}.svg')\n",
    "#     fig.savefig(output_path / f'auroc_{log_name}_{target_label}_{eval_name}.svg')\n",
    "    # plt.close(fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61d776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "for i in range(len(y_trues)):\n",
    "    fpr, tpr, _ = roc_curve(y_trues[i], y_preds[i])\n",
    "    roc_auc = roc_auc_score(y_trues[i], y_preds[i])\n",
    "    \n",
    "#     ax.plot(fpr, tpr, label=f'AUC = {roc_auc:0.2f}', alpha=0.3, color='black')\n",
    "\n",
    "\n",
    "    interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(roc_auc)\n",
    "ax.plot([0, 1], [0, 1], linestyle=\"--\", lw=1, color=\"gray\", label=\"Chance\", alpha=0.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "# plot mean curve\n",
    "ax.plot(\n",
    "    mean_fpr,\n",
    "    mean_tpr,\n",
    "    color=\"black\",\n",
    "    label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.3f)\" % (np.round(mean_auc, 2), np.round(std_auc, 3)),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(\n",
    "    mean_fpr,\n",
    "    tprs_lower,\n",
    "    tprs_upper,\n",
    "    color=\"grey\",\n",
    "    alpha=0.5,\n",
    "    label=r\"$\\pm$ 1 std. dev.\",\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05],\n",
    "    title=f\"ROC for {test_cohorts} (target: {cfg.target})\",\n",
    ")\n",
    "\n",
    "ax.set_xlabel('1 - Specificity')\n",
    "ax.set_ylabel('Sensitivity')\n",
    "\n",
    "ax.legend(loc=\"lower right\")\n",
    "# fig.savefig(output_path / f'auroc_{log_name}_{target_label}_{eval_name}.svg', format='svg', bbox_inches = 'tight', pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06221e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11183e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "\n",
    "for i in range(len(y_trues)):\n",
    "    fpr, tpr, _ = roc_curve(y_trues[i], y_preds[i])\n",
    "    roc_auc = roc_auc_score(y_trues[i], y_preds[i])\n",
    "    \n",
    "    ax.plot(fpr, tpr, lw=1, label=f'AUC = {roc_auc:0.2f}', color=pl.cm.viridis(i*(1/len(y_trues))))\n",
    "\n",
    "    interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(roc_auc)\n",
    "ax.plot([0, 1], [0, 1], linestyle=\"--\", lw=1, color=\"gray\", label=\"Chance\", alpha=0.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "# plot mean curve\n",
    "ax.plot(\n",
    "    mean_fpr,\n",
    "    mean_tpr,\n",
    "    color=\"black\",\n",
    "    label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.3f)\" % (mean_auc, std_auc),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "# std_tpr = np.std(tprs, axis=0)\n",
    "# tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "# tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "# ax.fill_between(\n",
    "#     mean_fpr,\n",
    "#     tprs_lower,\n",
    "#     tprs_upper,\n",
    "#     color=\"grey\",\n",
    "#     alpha=0.5,\n",
    "#     label=r\"$\\pm$ 1 std. dev.\",\n",
    "# )\n",
    "\n",
    "ax.set(\n",
    "    xlim=[0., .4],\n",
    "    ylim=[0.6, 1.],\n",
    ")\n",
    "\n",
    "# ax.set_xlabel('1 - Specificity')\n",
    "# ax.set_ylabel('Sensitivity')\n",
    "\n",
    "# ax.legend(loc=\"lower right\")\n",
    "# fig.savefig(output_path / f'auroc_{log_name}_{target_label}_{eval_name}_zoom.svg',  format='svg', bbox_inches = 'tight', pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a11224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ff32ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dfs = [pd.read_csv(p, dtype=str) for p in pred_csvs]\n",
    "\n",
    "y_trues = [df[\"ground_truth\"] == f'{true_label:.1f}' for df in pred_dfs]\n",
    "y_preds = [pd.to_numeric(df[f'logits']) for df in pred_dfs]\n",
    "title = f'{cfg.target} = {true_label}'\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "if len(pred_dfs) == 1:\n",
    "    plot_precision_recall_curve(ax, y_trues[0], y_preds[0], title=title)\n",
    "else:\n",
    "    plot_precision_recall_curves(ax, y_trues, y_preds, title=title)\n",
    "\n",
    "# fig.savefig(Path(output_path)/f'prc_{log_name}_{target_label}={true_label}_{eval_name}.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dd5c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "precs = []\n",
    "aucs = []\n",
    "mean_recall = np.linspace(0, 1, 100)\n",
    "\n",
    "y_trues = [df[\"ground_truth\"] == f'{true_label:.1f}' for df in pred_dfs]\n",
    "y_preds = [pd.to_numeric(df[f'logits']) for df in pred_dfs]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "for i in range(len(y_trues)):\n",
    "    prec, rec, _ = precision_recall_curve(y_trues[i], y_preds[i])\n",
    "    prec, rec = prec[::-1], rec[::-1]  # reverse order for interp\n",
    "    pr_auc = average_precision_score(y_trues[i], y_preds[i])\n",
    "    \n",
    "    ax.plot(rec, prec, label=f'AUC = {pr_auc:0.2f}', color=pl.cm.viridis(i*(1/len(y_trues))))\n",
    "    \n",
    "    baseline = y_trues[i].sum()/len(y_trues[i])\n",
    "\n",
    "    interp_prec = np.interp(mean_recall, rec, prec)\n",
    "    interp_prec[0] = 0.0\n",
    "#     print(interp_prec[:20])\n",
    "#     print(rec[:20])\n",
    "#     print(prec[:20])\n",
    "    precs.append(interp_prec)\n",
    "    aucs.append(pr_auc)\n",
    "    \n",
    "y_trues = np.concatenate(y_trues, dtype=int)\n",
    "y_preds = np.concatenate(y_preds, dtype=float)\n",
    "prec, rec, _ = precision_recall_curve(y_trues, y_preds)\n",
    "\n",
    "pr_auc = average_precision_score(y_trues, y_preds)\n",
    "\n",
    "ax.plot([0, 1], [baseline, baseline], '--', label=\"Chance\", alpha=0.8, color=\"gray\", lw=1)\n",
    "\n",
    "\n",
    "# mean_prec = np.mean(precs, axis=0)\n",
    "# mean_prec[-1] = 1.0\n",
    "# mean_auc = auc(mean_prec, mean_recall)\n",
    "# std_auc = np.std(aucs)\n",
    "# # plot mean curve\n",
    "# ax.plot(\n",
    "#     mean_recall,\n",
    "#     mean_prec,\n",
    "#     color=\"b\",\n",
    "#     label=r\"Mean PRC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n",
    "#     lw=2,\n",
    "#     alpha=0.8,\n",
    "# )\n",
    "\n",
    "# std_precisions = np.std(precisions, axis=0)\n",
    "# prec_upper = np.minimum(mean_prec + std_precisions, 1)\n",
    "# prec_lower = np.maximum(mean_prec - std_precisions, 0)\n",
    "# ax.fill_between(\n",
    "#     mean_prec,\n",
    "#     prec_lower,\n",
    "#     prec_upper,\n",
    "#     color=\"grey\",\n",
    "#     alpha=0.2,\n",
    "#     label=r\"$\\pm$ 1 std. dev.\",\n",
    "# )\n",
    "\n",
    "ax.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05],\n",
    "    title=f\"PRC for {test_cohorts} (target: {cfg.target})\",\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "\n",
    "ax.legend(loc=\"lower left\")\n",
    "# fig.savefig(output_path / f'prauc_{log_name}_{target_label}_{eval_name}.svg', format='svg', bbox_inches = 'tight', pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691cd1ec",
   "metadata": {},
   "source": [
    "### restrict patients (to age condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b617690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of patients with age under 50\n",
    "# cohort = 'Yorkshire-resections'\n",
    "# cohort = 'Dachs'\n",
    "# cohort_label = 'DACHS'\n",
    "cohort = 'Quasar'\n",
    "cohort_label = 'QUASAR'\n",
    "# cohort = 'TCGA'\n",
    "norm = 'macenko'\n",
    "feats = 'ctranspath'\n",
    "target_labels = ['isMSIH']\n",
    "categories = ['Not mut.', 'Mutat.', 'nonMSIH', 'MSIH', 'WT', 'MUT', 'wt', 'MT']\n",
    "clini_info = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899d1060",
   "metadata": {},
   "outputs": [],
   "source": [
    "clini_table = MSI_cohorts_munich[cohort]['clini_table']\n",
    "slide_csv = MSI_cohorts_munich[cohort]['slide_csv']\n",
    "feature_dir = MSI_cohorts_munich[cohort]['feature_dir'][norm][feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391de8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clini_df = pd.read_csv(clini_table, dtype=str) if Path(clini_table).suffix == '.csv' else pd.read_excel(\n",
    "    clini_table, dtype=str)\n",
    "slide_df = pd.read_csv(slide_csv, dtype=str)\n",
    "df = clini_df.merge(slide_df, on='PATIENT')\n",
    "# adapt dataframe to case sensitive clini tables\n",
    "df = df.rename({\n",
    "    'MSI': 'isMSIH',\n",
    "    'BRAF': 'braf', 'BRAF_mutation': 'braf', 'braf_status': 'braf', \n",
    "    'KRAS': 'kras', 'kras_status': 'kras', 'KRAS_mutation': 'kras',\n",
    "    'NRAS': 'nras', 'NRAS_mutation': 'nras',  \n",
    "}, axis=1)\n",
    "\n",
    "# remove columns not in target_labels\n",
    "for key in df.columns:\n",
    "    if key not in target_labels + ['PATIENT', 'SLIDE', 'FILENAME', 'AGE', 'GENDER', 'LEFT_RIGHT']:\n",
    "        df.drop(key, axis=1, inplace=True)\n",
    "# remove rows/slides with non-valid labels\n",
    "for target in target_labels:\n",
    "    df = df[df[target].isin(categories)]\n",
    "if clini_info:\n",
    "    df = df[df['GENDER'].isin(['female', 'male'])]\n",
    "    df = df[df['AGE'].str.isdigit()]\n",
    "    df = df[df['LEFT_RIGHT'].isin(['left', 'right'])]\n",
    "# remove slides we don't have\n",
    "h5s = set(feature_dir.glob('*.h5'))\n",
    "assert h5s, f'no features found in {feature_dir}!'\n",
    "h5_df = pd.DataFrame(h5s, columns=['slide_path'])\n",
    "# h5_df['FILENAME'] = h5_df.slide_path.map(lambda p: p.stem.split('.')[0])\n",
    "h5_df['FILENAME'] = h5_df.slide_path.map(lambda p: p.stem.split('.')[0]) if cohort=='TCGA' else h5_df.slide_path.map(lambda p: p.stem)\n",
    "df = df.merge(h5_df, on='FILENAME')\n",
    "\n",
    "# reduce to one row per patient with list of slides in `df['slide_path']`\n",
    "patient_df = df.groupby('PATIENT').first().drop(columns='slide_path')\n",
    "patient_slides = df.groupby('PATIENT').slide_path.apply(list)\n",
    "df = patient_df.merge(patient_slides, left_on='PATIENT', right_index=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e9becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni = df['AGE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdd864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e82e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a10165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new['AGE'] = new['AGE'].astype(int)\n",
    "df['AGE'] = df['AGE'].astype(int)\n",
    "df = df.drop('isMSIH', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b03427",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d62b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['AGE'] < 50]\n",
    "df = df[df['AGE'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026c5633",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c676454",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dfs = [pd.read_csv(p, dtype=str) for p in pred_csvs]\n",
    "pred_dfs = [pd.merge(pred_dfs[i], df, on=\"PATIENT\", how='inner') for i in range(len(pred_dfs))]\n",
    "\n",
    "y_trues = [df[target_label] == f'{true_label}' for df in pred_dfs]\n",
    "y_preds = [pd.to_numeric(df[f'score']) for df in pred_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a9bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "for i in range(len(y_trues)):\n",
    "    fpr, tpr, _ = roc_curve(y_trues[i], y_preds[i])\n",
    "    roc_auc = roc_auc_score(y_trues[i], y_preds[i])\n",
    "    \n",
    "#     ax.plot(fpr, tpr, label=f'AUC = {roc_auc:0.2f}', alpha=0.3, color='black')\n",
    "\n",
    "\n",
    "    interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(roc_auc)\n",
    "ax.plot([0, 1], [0, 1], linestyle=\"--\", lw=1, color=\"gray\", label=\"Chance\", alpha=0.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "# plot mean curve\n",
    "ax.plot(\n",
    "    mean_fpr,\n",
    "    mean_tpr,\n",
    "    color=\"black\",\n",
    "    label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.3f)\" % (mean_auc, std_auc),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(\n",
    "    mean_fpr,\n",
    "    tprs_lower,\n",
    "    tprs_upper,\n",
    "    color=\"grey\",\n",
    "    alpha=0.5,\n",
    "    label=r\"$\\pm$ 1 std. dev.\",\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05],\n",
    "    title=f\"ROC for patients with age < 50 from {cohort_label} (n={len(df)})\",\n",
    ")\n",
    "\n",
    "ax.set_xlabel('1 - Specificity')\n",
    "ax.set_ylabel('Sensitivity')\n",
    "\n",
    "ax.legend(loc=\"lower right\")\n",
    "fig.savefig(output_path / f'auroc_{log_name}_{target_label}_{eval_name}_under50.svg', format='svg', bbox_inches = 'tight', pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21485b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(0.45*5,0.75*5))\n",
    "\n",
    "for i in range(len(y_trues)):\n",
    "    fpr, tpr, _ = roc_curve(y_trues[i], y_preds[i])\n",
    "    roc_auc = roc_auc_score(y_trues[i], y_preds[i])\n",
    "    \n",
    "    ax.plot(fpr, tpr, lw=1, label=f'AUC = {roc_auc:0.2f}', color=pl.cm.viridis(i*(1/len(y_trues))))\n",
    "\n",
    "    interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(roc_auc)\n",
    "ax.plot([0, 1], [0, 1], linestyle=\"--\", lw=1, color=\"gray\", label=\"Chance\", alpha=0.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "# plot mean curve\n",
    "ax.plot(\n",
    "    mean_fpr,\n",
    "    mean_tpr,\n",
    "    color=\"black\",\n",
    "    label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.3f)\" % (mean_auc, std_auc),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "# std_tpr = np.std(tprs, axis=0)\n",
    "# tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "# tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "# ax.fill_between(\n",
    "#     mean_fpr,\n",
    "#     tprs_lower,\n",
    "#     tprs_upper,\n",
    "#     color=\"grey\",\n",
    "#     alpha=0.5,\n",
    "#     label=r\"$\\pm$ 1 std. dev.\",\n",
    "# )\n",
    "\n",
    "ax.set(\n",
    "    xlim=[0.0, .45],\n",
    "    ylim=[0.25, 1.],\n",
    ")\n",
    "\n",
    "# ax.set_xlabel('1 - Specificity')\n",
    "# ax.set_ylabel('Sensitivity')\n",
    "\n",
    "# ax.legend(loc=\"lower right\")\n",
    "fig.savefig(output_path / f'auroc_{log_name}_{target_label}_{eval_name}_under50_zoom.svg',  format='svg', bbox_inches = 'tight', pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166173df",
   "metadata": {},
   "source": [
    "# Plot confusion matrix, analyze sensitifity and specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94901382",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dir = Path('/lustre/groups/peng/workspace/sophia.wagner/logs/genalt/outputs')\n",
    "\n",
    "# model paths ---------------------------------------------------------------\n",
    "# --- for MSI-H\n",
    "# log_name = 'ctranspath_8epo_vit-cls_rand867_Dachs-Quasar-Rainbow-TCGA_macenko' # model for MSI-H\n",
    "# log_name = 'histaugan_rand867_vit-cls_Dachs-Quasar-Rainbow-TCGA_histaugan' # histaugan model for MSI-H\n",
    "log_name = 'raw_rand867_vit-cls_Dachs-Quasar-Rainbow-TCGA_raw' # raw model for MSI-H\n",
    "# --- for BRAF and KRAS\n",
    "# log_name = 'ctranspath_8epo_vit-cls_Dachs-Quasar-Rainbow-TCGA_macenko'  # model for BRAF and KRAS\n",
    "# --- for age < 50\n",
    "# log_name = 'ctranspath_epo8_vit-cls_Dachs_macenko' # model for age < 50\n",
    "# log_name = 'ctranspath_epo8_vit-cls_Quasar_macenko' # model for age < 50\n",
    "\n",
    "# cohort for evaluation -------------------------------------------------------\n",
    "eval_name = 'Yorkshire-resections'\n",
    "eval_name_label = 'YCR-BCIP'\n",
    "cmap = plt.cm.Blues\n",
    "# eval_name = 'Yorkshire-biopsies'\n",
    "# eval_name_label = 'YCR-BCIP-biopsies'\n",
    "# cmap = plt.cm.Greens\n",
    "# eval_name = 'Quasar'\n",
    "# eval_name = 'Dachs'\n",
    "# eval_name = 'Belfast'\n",
    "# eval_name_label = 'Epi700'\n",
    "# eval_name = 'KIEL-STAD'\n",
    "\n",
    "# target label ---------------------------------------------------------------\n",
    "target_label = 'isMSIH'\n",
    "target_label_name = 'MSI-H'\n",
    "# target_label = 'braf'\n",
    "# target_label_name = 'BRAF'\n",
    "# target_label = 'kras'\n",
    "# target_label_name = 'KRAS'\n",
    "true_label = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addd9724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_paths = csv_dir.glob(f'outputs_{log_name}_{target_label}_fold*.csv')\n",
    "csv_paths = csv_dir.glob(f'outputs_{log_name}_{target_label}_fold*_eval_{eval_name}.csv')\n",
    "pred_csvs = list(csv_paths)\n",
    "# pred_csvs = [csv_dir / f'outputs_{log_name}_{target_label}_fold{k}.csv' for k in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a75233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dfs = [pd.read_csv(p, dtype=str) for p in pred_csvs]\n",
    "\n",
    "y_trues = [df[target_label] == f'{true_label}' for df in pred_dfs]\n",
    "y_preds = [pd.to_numeric(df[f'score']) for df in pred_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b1ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_sensitivity = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc11da2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine classification threshold on test data\n",
    "thresholds_test = []\n",
    "sensitivity = []\n",
    "specificity = []\n",
    "# Calculate the ROC curve\n",
    "for k in range(5):\n",
    "    fpr, tpr, thresholds = roc_curve(y_trues[k], y_preds[k])\n",
    "\n",
    "    # Find the threshold for a desired sensitivity\n",
    "    thresholds_test.append(thresholds[tpr >= desired_sensitivity][0])\n",
    "    sensitivity.append(tpr[tpr >= desired_sensitivity][0])\n",
    "    specificity.append(1-fpr[tpr >= desired_sensitivity][0])\n",
    "#     print(1-fpr[tpr >= 0.95])\n",
    "\n",
    "threshold_test = np.array(thresholds_test).mean()\n",
    "# Print the threshold\n",
    "print(f\"Mean treshold for desired sensitivity of {desired_sensitivity:.2f}: {np.array(thresholds_test).mean():.4f}\")\n",
    "print(f\"The model achieves sensitivity: {np.array(sensitivity).mean():.4f} with specificty {np.array(specificity).mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb79b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_paths_train = csv_dir.glob(f'outputs_{log_name}_{target_label}_fold*.csv')\n",
    "pred_csvs_train = list(csv_paths_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62570c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dfs_train = [pd.read_csv(p, dtype=str) for p in pred_csvs_train]\n",
    "\n",
    "y_trues_train = [df[target_label] == f'{true_label}' for df in pred_dfs_train]\n",
    "y_preds_train = [pd.to_numeric(df[f'score']) for df in pred_dfs_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45fec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine best fold according to AUROC score\n",
    "rocs = []\n",
    "for i in range(len(y_trues)):\n",
    "#     rocs.append(roc_auc_score(y_trues[i], y_preds[i])) \n",
    "    rocs.append(roc_auc_score(y_trues_train[i], y_preds_train[i]))\n",
    "best_fold = np.argmax(rocs)\n",
    "print(f'best fold: {best_fold}, with AUROC {rocs[best_fold]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91f40dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f745835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine classification threshold on test data\n",
    "thresholds_train = []\n",
    "sensitivity_indomain = []\n",
    "specificity_indomain =[]\n",
    "\n",
    "sensitivity = []\n",
    "specificity =[]\n",
    "# Calculate the ROC curve\n",
    "for k in range(5):\n",
    "    fpr_indomain, tpr_indomain, thresholds_indomain = roc_curve(y_trues_train[k], y_preds_train[k])\n",
    "    fpr, tpr, thresholds = roc_curve(y_trues[k], y_preds[k])\n",
    "\n",
    "    # Find the threshold for a desired sensitivity\n",
    "    thresholds_train.append(thresholds_indomain[tpr_indomain >= desired_sensitivity][0])\n",
    "    sensitivity_indomain.append(tpr_indomain[tpr_indomain >= desired_sensitivity][0])\n",
    "    specificity_indomain.append(1-fpr_indomain[tpr_indomain >= desired_sensitivity][0])\n",
    "    \n",
    "    sensitivity.append(tpr[thresholds >= thresholds_train[k]][-1])\n",
    "    specificity.append(1-fpr[thresholds >= thresholds_train[k]][-1])\n",
    "    \n",
    "threshold_train = np.array(thresholds_train).mean()\n",
    "# Print the threshold\n",
    "print(f\"Mean treshold for desired sensitivity of {desired_sensitivity:.2f}: {np.array(thresholds_train).mean():.4f}\")\n",
    "print(f\"Sensitivity (with in-domain threshold): {np.array(sensitivity_indomain).mean():.4f} with specificty {np.array(specificity_indomain).mean():.4f}\")\n",
    "print(f\"Sensitivity (with external threshold): {np.array(sensitivity).mean():.4f} with specificty {np.array(specificity).mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f30ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "npv = []\n",
    "for k in range(5):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_trues[k], y_preds[k] > thresholds_train[k]).flatten()\n",
    "    npv.append(tn / (tn + fn))\n",
    "print(f\"Negative predictive value (with in-domain threshold): {np.array(npv).mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f9eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "npv = []\n",
    "for k in range(5):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_trues[k], y_preds[k] > thresholds_test[k]).flatten()\n",
    "    npv.append(tn / (tn + fn))\n",
    "print(f\"Negative predictive value (with external threshold): {np.array(npv).mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9b17ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_train, threshold_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb6e1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine negative predictive value\n",
    "print(f\"Negative predictive value (with in-domain threshold): {np.array(specificity_indomain).mean()/(1-np.array(sensitivity_indomain).mean()):.4f}\")\n",
    "print(f\"Negative predictive value (with external threshold): {np.array(specificity).mean()/(1-np.array(sensitivity).mean()):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89058319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class labels\n",
    "labels = [\"non MSIH\", \"MSIH\"]\n",
    "\n",
    "# Calculate the confusion matrix for different classification thresholds\n",
    "# thresholds_test = np.array(thresholds_test).mean().repeat(5)\n",
    "# thresholds_train = np.array(thresholds_train).mean().repeat(5)\n",
    "thresholds = [thresholds_test, [0.25] * 5, [0.5] * 5, [0.75] * 5, thresholds_train]\n",
    "\n",
    "# Plot the confusion matrices\n",
    "fig, axs = plt.subplots(1, len(thresholds), figsize=(12,10), gridspec_kw={'width_ratios': [4, 4, 4, 4, 4.4]})\n",
    "for ax, threshold in zip(axs.flatten(), thresholds):\n",
    "    cm = []\n",
    "    for k in range(5):\n",
    "        cm.append(confusion_matrix(y_trues[k], y_preds[k] > threshold[k]))\n",
    "    cm = np.stack(cm, axis=0).mean(axis=0)    \n",
    "    print(threshold[k])\n",
    "#     cm = confusion_matrix(y_trues[best_fold], y_preds[best_fold] > threshold)\n",
    "\n",
    "    # Normalize the confusion matrices by the row\n",
    "    cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm_perc = cm.astype(\"float\") / cm.sum(axis=(0, 1))[np.newaxis, np.newaxis]\n",
    "\n",
    "    im = ax.imshow(cm_normalized, interpolation='nearest', cmap=cmap)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=labels, yticklabels=labels,\n",
    "           title=f\"Threshold = {threshold[k]:.2f}\",\n",
    "#            ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    ax.set_yticklabels(labels, rotation='vertical', va='center', ha='center')\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            color = \"w\" if cm_normalized[i, j] > 0.5 else \"k\"\n",
    "            ax.text(j, i, int(cm[i, j].round()), ha=\"center\", va=\"bottom\", color=color)\n",
    "            ax.text(j, i, f'{cm_normalized[i, j]*100:.01f}%', ha=\"center\", va=\"top\", color=color)\n",
    "#             ax.text(j, i, f'{cm_perc[i, j]*100:.01f}%', ha=\"center\", va=\"top\", color=color)\n",
    "\n",
    "cbar = fig.colorbar(im, ax=axs[-1], fraction=0.046, pad=0.04, ticks=[0.02, 0.2, 0.4, 0.6, 0.8, 0.98])\n",
    "cbar.ax.set_yticklabels(np.linspace(0, 1, 6, dtype=np.float16))  # horizontal colorbar\n",
    "axs[0].set(ylabel='True label')\n",
    "axs[0].set(title='External threshold')\n",
    "axs[-1].set(title='In-domain threshold')\n",
    "# plt.tight_layout()\n",
    "fig.savefig(output_path / f'confusion_matrices_{log_name}_{target_label}_{eval_name}_mean.svg',  format='svg', bbox_inches = 'tight', pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0453d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.astype(\"float\") / cm.sum(axis=(0, 1))[np.newaxis, np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c70fdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(thresholds_test).mean().repeat(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1d5fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class labels\n",
    "labels = [\"non MSIH\", \"MSIH\"]\n",
    "\n",
    "# Calculate the confusion matrix for different classification thresholds\n",
    "# threshsolds = [np.array(thresholds_test).mean()]\n",
    "thresholds = [thresholds_test, [0.25] * 5, [0.5] * 5, [0.75] * 5, thresholds_train]\n",
    "\n",
    "# Plot the confusion matrices\n",
    "fig, axs = plt.subplots(5, len(thresholds), figsize=(12,15), gridspec_kw={'width_ratios': [4, 4, 4, 4, 4.4]})\n",
    "for k in range(5):\n",
    "    for t in range(5):\n",
    "        cm = confusion_matrix(y_trues[k], y_preds[k] > thresholds[t][k])\n",
    "        print(t, k, thresholds[t][k], cm.sum(axis=1))\n",
    "\n",
    "        # Normalize the confusion matrices by the row\n",
    "        cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "        im = axs[k, t].imshow(cm_normalized, interpolation='nearest', cmap=cmap)\n",
    "        axs[k, t].set(xticks=np.arange(cm.shape[1]),\n",
    "               yticks=np.arange(cm.shape[0]),\n",
    "               xticklabels=labels, yticklabels=labels,\n",
    "               title=f\"Threshold = {thresholds[t][k]:.2f}\",\n",
    "    #            ylabel='True label',\n",
    "               xlabel='Predicted label')\n",
    "        axs[k, t].set_yticklabels(labels, rotation='vertical', va='center', ha='center')\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                color = \"w\" if cm_normalized[i, j] > 0.5 else \"k\"\n",
    "                axs[k, t].text(j, i, int(cm[i, j].round()), ha=\"center\", va=\"bottom\", color=color)\n",
    "                axs[k, t].text(j, i, f'{cm_normalized[i, j]*100:.01f}%', ha=\"center\", va=\"top\", color=color)\n",
    "\n",
    "    cbar = fig.colorbar(im, ax=axs[k, 4], fraction=0.046, pad=0.04, ticks=[0.02, 0.2, 0.4, 0.6, 0.8, 0.98])\n",
    "    cbar.ax.set_yticklabels(np.linspace(0, 1, 6, dtype=np.float16))  # horizontal colorbar\n",
    "    axs[k, 0].set(ylabel='True label')\n",
    "    axs[k, 0].set(title=f'Ext. thresh. ({thresholds[0][k]:.03f})')\n",
    "    axs[k, 4].set(title=f'In-dom. thresh. ({thresholds[4][k]:.03f})')\n",
    "# plt.tight_layout()\n",
    "fig.savefig(output_path / f'confusion_matrices_{log_name}_{target_label}_{eval_name}_all_folds.svg',  format='svg', bbox_inches = 'tight', pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e312e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfeba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "# Split the predictions and labels by label\n",
    "preds_0 = y_preds[best_fold][y_trues[best_fold] == 0]\n",
    "preds_1 = y_preds[best_fold][y_trues[best_fold] == 1]\n",
    "\n",
    "# Plot the histograms\n",
    "plt.hist([preds_0, preds_1], bins=50, density=True, label=[\"nonMSIH\", \"MSIH\"])\n",
    "# plt.hist([preds_0, preds_1], bins=50, density=False, label=[\"nonMSIH\", \"MSIH\"], alpha=0.2)\n",
    "plt.xlabel(\"Prediction\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f15ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "\n",
    "# Set up the subplots\n",
    "fig, axs = plt.subplots(1, num_folds, figsize=(num_folds * 5, 5))\n",
    "\n",
    "# Plot the histograms for each model\n",
    "for k, ax, in enumerate(axs):\n",
    "    preds_0 = y_preds[k][y_trues[k] == 0]\n",
    "    preds_1 = y_preds[k][y_trues[k] == 1]\n",
    "    \n",
    "    ax.hist([preds_0, preds_1], bins=50, density=True, label=[\"nonMSIH\", \"MSIH\"])\n",
    "    ax.set_xlabel(\"Prediction\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e33fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1c9873",
   "metadata": {},
   "source": [
    "# plot num samples curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402fc146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_path = Path('/lustre/groups/peng/workspace/sophia.wagner/logs/genalt/results')\n",
    "dir_path = Path('/home/haicu/sophia.wagner/projects/genetic_alteration_prediction')\n",
    "ext_cohort = 'Yorkshire_resections'\n",
    "# ext_cohort = 'Yorkshire_biopsies'\n",
    "model = 'transformer'\n",
    "feats = 'ctranspath'\n",
    "# ext_cohort = 'Yorkshire_resections'\n",
    "filename = dir_path / f'MSI_prediction_num_samples_{ext_cohort}_{model}_{feats}.csv'\n",
    "num_df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4d78fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#             # save results in data frame \n",
    "#             for ext_cohort in ext_cohorts:\n",
    "#                 results_csv = result_path / f'results_num_samples_{ext_cohort}_{args.model}_{args.feats}{args.name}.csv'\n",
    "#                 columns = [\"num samples\"] + [f'fold {i}' for i in range(5)]\n",
    "#                 new_results = pd.DataFrame(data=np.array([[n, *ext_auc_dict[ext_cohort][n]]]), columns=columns)\n",
    "\n",
    "#                 # append results to existing results data frame\n",
    "#                 if results_csv.is_file():\n",
    "#                     results_df = pd.read_csv(results_csv, dtype=str)\n",
    "#                     if n in results_df[\"num samples\"]:\n",
    "#                         continue\n",
    "#                     else:\n",
    "#                         results_df = results_df.append(new_results)\n",
    "#                 else:\n",
    "#                     results_df = new_results\n",
    "\n",
    "#                 results_df.to_csv(results_csv, sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560cbf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cohort for evaluation\n",
    "# ext_cohort = 'Yorkshire-resections'\n",
    "ext_cohort = 'Yorkshire-biopsies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3bca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'vit-cls'\n",
    "feats = 'ctranspath'\n",
    "name = ''\n",
    "\n",
    "label = 'Macenko'\n",
    "\n",
    "result_path = Path('/lustre/groups/peng/workspace/sophia.wagner/logs/genalt/results')\n",
    "filename = result_path / f'results_num_samples_{ext_cohort}_{model}_{feats}{name}.csv'\n",
    "\n",
    "num_df = pd.read_csv(filename)\n",
    "num_df = num_df.rename({'fold 4 ': 'fold 4'}, axis=1)\n",
    "num_df = num_df.rename({'training samples': 'num samples'}, axis=1)\n",
    "num_df = num_df.sort_values(by='num samples')\n",
    "num_df = num_df.drop_duplicates(subset='num samples')\n",
    "num_samples_array = [num_df[f'fold {i}'].values for i in range(5)]\n",
    "num_samples_x = num_df['num samples'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0c9f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = 'attmil'\n",
    "model = 'vit-cls'\n",
    "feats = 'ctranspath'\n",
    "name = '_histaugan'\n",
    "\n",
    "label2 = 'HistAuGAN'\n",
    "\n",
    "filename = result_path / f'results_num_samples_{ext_cohort}_{model}_{feats}{name}.csv'\n",
    "\n",
    "num_df2 = pd.read_csv(filename)\n",
    "num_df2 = num_df2.rename({'fold 4 ': 'fold 4'}, axis=1)\n",
    "num_df2 = num_df2.rename({'training samples': 'num samples'}, axis=1)\n",
    "num_df2 = num_df2.sort_values(by='num samples')\n",
    "num_df2 = num_df2.drop_duplicates(subset='num samples')\n",
    "num_samples_array2 = [num_df2[f'fold {i}'].values for i in range(5)]\n",
    "num_samples_x2 = num_df2['num samples'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac317f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bc0992",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2013c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "# plt.boxplot(np.stack(num_samples_array), labels=np.array(num_df['num_samples'], dtype=float), widths=0.2, showmeans=True, meanline=True)\n",
    "# for i in range(5):\n",
    "#     plt.scatter(np.array(num_df['num_samples'], dtype=float), np.stack(num_samples_array)[i])\n",
    "# plt.plot(range(1, 16), np.mean(np.stack(num_samples_array), axis=0))\n",
    "\n",
    "plt.plot((0, 10000), (0.9, 0.9), linewidth=0.5, color='gray')\n",
    "plt.plot((0, 10000), (0.95, 0.95), linewidth=0.5, color='gray')\n",
    "# plt.plot((0, 10000), (0.95, 0.95), linestyle='--', linewidth=1, color='gray')\n",
    "\n",
    "\n",
    "num_samples = np.stack(num_samples_array)\n",
    "mean = num_samples.mean(axis=0)\n",
    "std = num_samples.std(axis=0)\n",
    "plt.plot(num_samples_x, mean, color='tab:blue', label=label)\n",
    "plt.plot((0, 10000), (0.9686, 0.9686), linestyle='--', linewidth=1, color='tab:blue', label='Best model')\n",
    "# plt.plot((0, 10000), (0.9072, 0.9072), linestyle='--', linewidth=1, color='tab:blue', label='Best model')\n",
    "plt.plot(num_samples_x, num_samples[0], alpha=0.3, color='tab:blue')\n",
    "plt.plot(num_samples_x, num_samples[1], alpha=0.3, color='tab:blue')\n",
    "plt.plot(num_samples_x, num_samples[2], alpha=0.3, color='tab:blue')\n",
    "plt.plot(num_samples_x, num_samples[3], alpha=0.3, color='tab:blue')\n",
    "plt.plot(num_samples_x, num_samples[4], alpha=0.3, color='tab:blue')\n",
    "plt.fill_between(num_samples_x, mean - std, mean + std, alpha=0.5, color='tab:blue')\n",
    "\n",
    "\n",
    "num_samples = np.stack(num_samples_array2)\n",
    "mean = num_samples.mean(axis=0)\n",
    "std = num_samples.std(axis=0)\n",
    "plt.plot(num_samples_x2, mean, color='tab:orange', label=label2)\n",
    "# plt.plot((0, 8000), (0.9633, 0.9633), linestyle='--', linewidth=1, color='tab:orange', label='Best model')\n",
    "plt.plot(num_samples_x2, num_samples[0], alpha=0.3, color='tab:orange')\n",
    "plt.plot(num_samples_x2, num_samples[1], alpha=0.3, color='tab:orange')\n",
    "plt.plot(num_samples_x2, num_samples[2], alpha=0.3, color='tab:orange')\n",
    "plt.plot(num_samples_x2, num_samples[3], alpha=0.3, color='tab:orange')\n",
    "plt.plot(num_samples_x2, num_samples[4], alpha=0.3, color='tab:orange')\n",
    "plt.fill_between(num_samples_x2, mean - std, mean + std, alpha=0.6, color='tab:orange')\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.ylim(0.5, 1)\n",
    "plt.yticks(ticks=np.linspace(0.5, 1, 11))\n",
    "plt.ylabel('AUROC')\n",
    "\n",
    "plt.xlim(min(num_samples_x)-2, max(num_samples_x)+2000)\n",
    "plt.xticks(ticks=num_samples_x, labels=[x for x in num_samples_x])\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Number of samples in the training set (log scale)')\n",
    "\n",
    "# plt.savefig(output_path / f'num_samples_{ext_cohort}.svg', format='svg', bbox_inches = 'tight', pad_inches = 0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11869c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = np.stack(num_samples_array)\n",
    "mean = num_samples.mean(axis=0)\n",
    "std = num_samples.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8627278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4de35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf80aaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = np.stack(num_samples_array)\n",
    "mean = num_samples.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536ee00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, num_samples_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd749df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = np.stack(num_samples_array2)\n",
    "mean = num_samples.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25af967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, num_samples_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c59f6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ctp_n = np.array([50, 100, 250, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000])\n",
    "t_ctp = np.array([\n",
    "    [0.7652, 0.8778, 0.7515, 0.7836, 0.8378,],\n",
    "    [0.8041, 0.8283, 0.9115, 0.7765, 0.7524,],\n",
    "    [0.9340, 0.9329, 0.8734, 0.9070, 0.9298,],\n",
    "    [0.9313, 0.9485, 0.9064, 0.8828, 0.9169,],\n",
    "    [0.9601, 0.9477, 0.9599, 0.9544, 0.9588,],\n",
    "    [0.9452, 0.9513, 0.9575, 0.9680, 0.9475,],\n",
    "    [0.9634, 0.9727, 0.9631, 0.9518, 0.9489,],\n",
    "    [0.9676, 0.9677, 0.9551, 0.9600, 0.9635,],\n",
    "    [0.9583, 0.9637, 0.9565, 0.9655, 0.9591,],\n",
    "    [0.9619, 0.9637, 0.9707, 0.9633, 0.9654,],\n",
    "    [0.9657, 0.9573, 0.9683, 0.9726, 0.9583,],\n",
    "    [0.9647, 0.9672, 0.9729, 0.9700, 0.9651,],\n",
    "    [0.9668, 0.9768, 0.9703, 0.9613, 0.9647,],\n",
    "    [0.9669, 0.9682, 0.9604, 0.9667, 0.9594,],\n",
    "    [0.9728, 0.9702, 0.9682, 0.9746, 0.9663,],\n",
    "    [0.9636, 0.9646, 0.9696, 0.9785, 0.9730,],\n",
    "    [0.9709, 0.9702, 0.9705, 0.9781, 0.9679,],\n",
    "    [0.9724, 0.9662, 0.9677, 0.9711, 0.9741,],\n",
    "    [0.9692, 0.9684, 0.9706, 0.9590, 0.9686,],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a8af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = t_ctp\n",
    "mean = num_samples.mean(axis=1)\n",
    "std = num_samples.std(axis=1)\n",
    "plt.plot(t_ctp_n, mean)\n",
    "plt.plot(t_ctp_n, num_samples[:, 0], alpha=0.2)\n",
    "plt.plot(t_ctp_n, num_samples[:, 1], alpha=0.2)\n",
    "plt.plot(t_ctp_n, num_samples[:, 2], alpha=0.2)\n",
    "plt.plot(t_ctp_n, num_samples[:, 3], alpha=0.2)\n",
    "plt.plot(t_ctp_n, num_samples[:, 4], alpha=0.2)\n",
    "plt.fill_between(t_ctp_n, mean - std, mean + std, alpha=0.5)\n",
    "\n",
    "# plt.xlim(1, num_samples.shape[1]+1)\n",
    "plt.xticks(ticks=t_ctp_n) # labels=[x for x in range(500, num_samples.shape[1]*500+1, 500)])\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01896018",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = t_ctp\n",
    "mean = num_samples.mean(axis=1)\n",
    "std = num_samples.std(axis=1)\n",
    "plt.plot(t_ctp_n, mean)\n",
    "plt.plot(t_ctp_n, num_samples[:, 0], alpha=0.2)\n",
    "plt.plot(t_ctp_n, num_samples[:, 1], alpha=0.2)\n",
    "plt.plot(t_ctp_n, num_samples[:, 2], alpha=0.2)\n",
    "plt.plot(t_ctp_n, num_samples[:, 3], alpha=0.2)\n",
    "plt.plot(t_ctp_n, num_samples[:, 4], alpha=0.2)\n",
    "plt.fill_between(t_ctp_n, mean - std, mean + std, alpha=0.5)\n",
    "\n",
    "# plt.xlim(1, num_samples.shape[1]+1)\n",
    "plt.xticks(ticks=t_ctp_n) # labels=[x for x in range(500, num_samples.shape[1]*500+1, 500)])\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e440129b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380ccae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module for data manipulation\n",
    "import pandas as pd\n",
    "# Import module for linear algebra\n",
    "import numpy as np\n",
    "# Import module for data simulation\n",
    "from sklearn.datasets import make_classification     # Create a synthetic dataframe\n",
    "from sklearn.linear_model import LogisticRegression  # Classification model\n",
    "from sklearn.model_selection import train_test_split # Split the dataframe\n",
    "from sklearn.metrics import roc_curve                # Calculate the ROC curve\n",
    "from sklearn.metrics import precision_recall_curve   # Calculate the Precision-Recall curve\n",
    "from sklearn.metrics import f1_score                 # Calculate the F-score\n",
    "# Import module for data visualization\n",
    "from plotnine import *\n",
    "import plotnine\n",
    "\n",
    "# Generate the dataset\n",
    "X, y = make_classification(n_samples = 10000, n_features = 2, n_redundant = 0,\n",
    "                           n_clusters_per_class = 1, weights = [0.99], flip_y = 0, random_state = 0)\n",
    "\n",
    "# Data partitioning\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0, stratify=y)\n",
    "\n",
    "# Fit the model\n",
    "reglogModel = LogisticRegression(random_state = 0)\n",
    "reglogModel.fit(X_train, y_train)\n",
    "\n",
    "# Predict the probabilities\n",
    "y_pred = reglogModel.predict_proba(X_test)\n",
    "\n",
    "# Get the probabilities for positive class\n",
    "y_pred = y_pred[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a47114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "\n",
    "# Plot the ROC curve\n",
    "df_fpr_tpr = pd.DataFrame({'FPR':fpr, 'TPR':tpr, 'Threshold':thresholds})\n",
    "df_fpr_tpr.head()\n",
    "\n",
    "# Create the data viz\n",
    "plotnine.options.figure_size = (8, 4.8)\n",
    "(\n",
    "    ggplot(data = df_fpr_tpr)+\n",
    "    geom_point(aes(x = 'FPR',\n",
    "                   y = 'TPR'),\n",
    "               size = 0.4)+\n",
    "    geom_line(aes(x = 'FPR',\n",
    "                  y = 'TPR'))+\n",
    "    labs(title = 'ROC Curve')+\n",
    "    xlab('False Positive Rate')+\n",
    "    ylab('True Positive Rate')+\n",
    "    theme_minimal()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b06521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the G-mean\n",
    "gmean = np.sqrt(tpr * (1 - fpr))\n",
    "\n",
    "# Find the optimal threshold\n",
    "index = np.argmax(gmean)\n",
    "thresholdOpt = round(thresholds[index], ndigits = 4)\n",
    "gmeanOpt = round(gmean[index], ndigits = 4)\n",
    "fprOpt = round(fpr[index], ndigits = 4)\n",
    "tprOpt = round(tpr[index], ndigits = 4)\n",
    "print('Best Threshold: {} with G-Mean: {}'.format(thresholdOpt, gmeanOpt))\n",
    "print('FPR: {}, TPR: {}'.format(fprOpt, tprOpt))\n",
    "\n",
    "# Create data viz\n",
    "plotnine.options.figure_size = (8, 4.8)\n",
    "(\n",
    "    ggplot(data = df_fpr_tpr)+\n",
    "    geom_point(aes(x = 'FPR',\n",
    "                   y = 'TPR'),\n",
    "               size = 0.4)+\n",
    "    # Best threshold\n",
    "    geom_point(aes(x = fprOpt,\n",
    "                   y = tprOpt),\n",
    "               color = '#981220',\n",
    "               size = 4)+\n",
    "    geom_line(aes(x = 'FPR',\n",
    "                  y = 'TPR'))+\n",
    "    geom_text(aes(x = fprOpt,\n",
    "                  y = tprOpt),\n",
    "              label = 'Optimal threshold \\n for class: {}'.format(thresholdOpt),\n",
    "              nudge_x = 0.14,\n",
    "              nudge_y = -0.10,\n",
    "              size = 10,\n",
    "              fontstyle = 'italic')+\n",
    "    labs(title = 'ROC Curve')+\n",
    "    xlab('False Positive Rate (FPR)')+\n",
    "    ylab('True Positive Rate (TPR)')+\n",
    "    theme_minimal()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fa7db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sensitivity threshold\n",
    "sensitivity_thresh = 0.90\n",
    "\n",
    "# Find the optimal threshold\n",
    "index = np.argwhere(tpr >= sensitivity_thresh)[0].item()\n",
    "thresholdOpt = round(thresholds[index], ndigits = 4)\n",
    "gmeanOpt = round(gmean[index], ndigits = 4)\n",
    "fprOpt = round(fpr[index], ndigits = 4)\n",
    "tprOpt = round(tpr[index], ndigits = 4)\n",
    "print('Best Threshold: {} with G-Mean: {}'.format(thresholdOpt, gmeanOpt))\n",
    "print('FPR: {}, TPR: {}'.format(fprOpt, tprOpt))\n",
    "\n",
    "# Create data viz\n",
    "plotnine.options.figure_size = (8, 4.8)\n",
    "(\n",
    "    ggplot(data = df_fpr_tpr)+\n",
    "    geom_point(aes(x = 'FPR',\n",
    "                   y = 'TPR'),\n",
    "               size = 0.4)+\n",
    "    # Best threshold\n",
    "    geom_point(aes(x = fprOpt,\n",
    "                   y = tprOpt),\n",
    "               color = '#981220',\n",
    "               size = 4)+\n",
    "    geom_line(aes(x = 'FPR',\n",
    "                  y = 'TPR'))+\n",
    "    geom_text(aes(x = fprOpt,\n",
    "                  y = tprOpt),\n",
    "              label = 'Optimal threshold \\n for class: {}'.format(thresholdOpt),\n",
    "              nudge_x = 0.14,\n",
    "              nudge_y = -0.10,\n",
    "              size = 10,\n",
    "              fontstyle = 'italic')+\n",
    "    labs(title = 'ROC Curve')+\n",
    "    xlab('False Positive Rate (FPR)')+\n",
    "    ylab('True Positive Rate (TPR)')+\n",
    "    theme_minimal()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49d5715",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3d6827",
   "metadata": {},
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad01af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr[tpr >= 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61383b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr[tpr >= 0.9][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7558752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere(tpr >= 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449ae99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere(tpr >= 0.9)[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6553976",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds[np.where(tpr == tpr[tpr >= 0.9][0])[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad2e624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63febbde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77697acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd560b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'key':3}, {'te': 45\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c21a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d8f60b",
   "metadata": {},
   "source": [
    "# Data stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4821cf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import torch\n",
    "\n",
    "from data_utils import MSI_cohorts_munich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa4455d",
   "metadata": {},
   "source": [
    "## Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c4daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohorts = [\"Belfast\", \"CPTAC\", \"Dachs\", \"Duessel\", \"MECC\", \"Munich\", \"Quasar\", \"Rainbow\", \"TCGA\", \"Yorkshire-biopsies\", \"Yorkshire-resections\"]\n",
    "targets = ['', 'isMSIH', 'braf', 'kras']\n",
    "categories = ['Not mut.', 'Mutat.', 'nonMSIH', 'MSIH', 'WT', 'MUT', 'wt', 'MT']\n",
    "norm = \"macenko\"\n",
    "feats = \"ctranspath\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a214877",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cohort in cohorts:\n",
    "    cohort_dict = {}\n",
    "    for target in targets:\n",
    "        clini_table = MSI_cohorts_munich[cohort]['clini_table']\n",
    "        slide_csv = MSI_cohorts_munich[cohort]['slide_csv']\n",
    "        feature_dir = MSI_cohorts_munich[cohort]['feature_dir'][norm][feats]\n",
    "        \n",
    "        clini_df = pd.read_csv(clini_table, dtype=str) if Path(clini_table).suffix == '.csv' else pd.read_excel(\n",
    "            clini_table, dtype=str)\n",
    "        slide_df = pd.read_csv(slide_csv, dtype=str)\n",
    "        df = clini_df.merge(slide_df, on='PATIENT')\n",
    "        # adapt dataframe to case sensitive clini tables\n",
    "        df = df.rename({\n",
    "            'MSI': 'isMSIH',\n",
    "            'BRAF': 'braf', 'BRAF_mutation': 'braf', 'braf_status': 'braf', \n",
    "            'KRAS': 'kras', 'kras_status': 'kras', 'KRAS_mutation': 'kras',\n",
    "            'NRAS': 'nras', 'NRAS_mutation': 'nras',  \n",
    "        }, axis=1)\n",
    "\n",
    "        # remove columns not in target_labels\n",
    "        for key in df.columns:\n",
    "            keys = [target] + ['PATIENT', 'SLIDE', 'FILENAME'] if target != '' else ['PATIENT', 'SLIDE', 'FILENAME']\n",
    "            if key not in keys:\n",
    "                df.drop(key, axis=1, inplace=True)\n",
    "        # remove rows/slides with non-valid labels\n",
    "        if target == '' or target in df.keys():\n",
    "            if target != '':\n",
    "                for target in [target]:\n",
    "                    df = df[df[target].isin(categories)]\n",
    "    #         if self.clini_info:\n",
    "    #             df = df[df['GENDER'].isin(['female', 'male'])]\n",
    "    #             df = df[df['AGE'].str.isdigit()]\n",
    "    #             df = df[df['LEFT_RIGHT'].isin(['left', 'right'])]\n",
    "            # remove slides we don't have\n",
    "            h5s = set(feature_dir.glob('*.h5'))\n",
    "            assert h5s, f'no features found in {feature_dir}!'\n",
    "            h5_df = pd.DataFrame(h5s, columns=['slide_path'])\n",
    "            # h5_df['FILENAME'] = h5_df.slide_path.map(lambda p: p.stem.split('.')[0])\n",
    "            h5_df['FILENAME'] = h5_df.slide_path.map(lambda p: p.stem.split('.')[0]) if cohort=='TCGA' else h5_df.slide_path.map(lambda p: p.stem)\n",
    "            df = df.merge(h5_df, on='FILENAME')\n",
    "\n",
    "            # reduce to one row per patient with list of slides in `df['slide_path']`\n",
    "            patient_df = df.groupby('PATIENT').first().drop(columns='slide_path')\n",
    "            patient_slides = df.groupby('PATIENT').slide_path.apply(list)\n",
    "            df = patient_df.merge(patient_slides, left_on='PATIENT', right_index=True).reset_index()\n",
    "\n",
    "            if target != '':\n",
    "                assert len(df[target].unique()) == 2\n",
    "                pos_key = df[target].unique()[0] if df[target].unique()[0] in ['Mutat.', 'MSIH', 'MUT', 'MT'] else df[target].unique()[1]\n",
    "                pos = df[target].value_counts()[pos_key]\n",
    "            cohort_dict[target] = {\n",
    "                \"num\": len(df),\n",
    "                \"pos\": pos if target != '' else len(df)\n",
    "            }\n",
    "        else: \n",
    "            cohort_dict[target] = {\n",
    "                \"num\": 0,\n",
    "                \"pos\": 0\n",
    "            }\n",
    "            \n",
    "    print(f\"{cohort: <20}: total: {cohort_dict['']['num']}, \\\n",
    "          isMSIH: {cohort_dict['isMSIH']['pos']} / {cohort_dict['isMSIH']['num']}, \\\n",
    "          braf: {cohort_dict['braf']['pos']} / {cohort_dict['braf']['num']}, \\\n",
    "          kras: {cohort_dict['kras']['pos']} / {cohort_dict['kras']['num']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1665f2cf",
   "metadata": {},
   "source": [
    "## Tile distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b473ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohorts = [\"Belfast\", \"CPTAC\", \"Dachs\", \"Duessel\", \"MECC\", \"Munich\", \"Quasar\", \"Rainbow\", \"TCGA\", \"Yorkshire-biopsies\", \"Yorkshire-resections\"]\n",
    "target = 'isMSIH'\n",
    "categories = ['Not mut.', 'Mutat.', 'nonMSIH', 'MSIH', 'WT', 'MUT', 'wt', 'MT']\n",
    "norm = \"macenko\"\n",
    "feats = \"ctranspath\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17008dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_dict = {}\n",
    "for cohort in cohorts:\n",
    "    num_tiles = []\n",
    "\n",
    "    clini_table = MSI_cohorts_munich[cohort]['clini_table']\n",
    "    slide_csv = MSI_cohorts_munich[cohort]['slide_csv']\n",
    "    feature_dir = MSI_cohorts_munich[cohort]['feature_dir'][norm][feats]\n",
    "\n",
    "    clini_df = pd.read_csv(clini_table, dtype=str) if Path(clini_table).suffix == '.csv' else pd.read_excel(\n",
    "        clini_table, dtype=str)\n",
    "    slide_df = pd.read_csv(slide_csv, dtype=str)\n",
    "    df = clini_df.merge(slide_df, on='PATIENT')\n",
    "    # adapt dataframe to case sensitive clini tables\n",
    "    df = df.rename({\n",
    "        'MSI': 'isMSIH',\n",
    "        'BRAF': 'braf', 'BRAF_mutation': 'braf', 'braf_status': 'braf', \n",
    "        'KRAS': 'kras', 'kras_status': 'kras', 'KRAS_mutation': 'kras',\n",
    "        'NRAS': 'nras', 'NRAS_mutation': 'nras',  \n",
    "    }, axis=1)\n",
    "\n",
    "    # remove columns not in target_labels\n",
    "    for key in df.columns:\n",
    "        keys = [target] + ['PATIENT', 'SLIDE', 'FILENAME'] if target != '' else ['PATIENT', 'SLIDE', 'FILENAME']\n",
    "        if key not in keys:\n",
    "            df.drop(key, axis=1, inplace=True)\n",
    "    # remove rows/slides with non-valid labels\n",
    "    df = df[df[target].isin(categories)]\n",
    "    # remove slides we don't have\n",
    "    h5s = set(feature_dir.glob('*.h5'))\n",
    "    assert h5s, f'no features found in {feature_dir}!'\n",
    "    h5_df = pd.DataFrame(h5s, columns=['slide_path'])\n",
    "    # h5_df['FILENAME'] = h5_df.slide_path.map(lambda p: p.stem.split('.')[0])\n",
    "    h5_df['FILENAME'] = h5_df.slide_path.map(lambda p: p.stem.split('.')[0]) if cohort=='TCGA' else h5_df.slide_path.map(lambda p: p.stem)\n",
    "    df = df.merge(h5_df, on='FILENAME')\n",
    "\n",
    "    # reduce to one row per patient with list of slides in `df['slide_path']`\n",
    "    patient_df = df.groupby('PATIENT').first().drop(columns='slide_path')\n",
    "    patient_slides = df.groupby('PATIENT').slide_path.apply(list)\n",
    "    df = patient_df.merge(patient_slides, left_on='PATIENT', right_index=True).reset_index()\n",
    "\n",
    "    assert len(df[target].unique()) == 2\n",
    "\n",
    "    # count tiles \n",
    "    for p in tqdm(range(len(df))):\n",
    "        fpath = df.slide_path[p][0]\n",
    "        h5_file = h5py.File(fpath)\n",
    "        features = torch.Tensor(np.array(h5_file['feats'])).unsqueeze(0)\n",
    "        num_tiles.append(features.shape[1])\n",
    "    \n",
    "    cohort_dict[cohort] = num_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814b74eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cohort in cohorts:\n",
    "    num_tiles = np.array(cohort_dict[cohort])\n",
    "    print(cohort, num_tiles.mean().round(), num_tiles.std().round(), num_tiles.min(), num_tiles.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a9495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {\n",
    "    \"CPTAC\": \"CPTAC\", \n",
    "    \"Dachs\" : \"DACHS\", \n",
    "    \"Duessel\": \"DUSSEL\", \n",
    "    \"Belfast\": \"Epi700\", \n",
    "    \"MECC\": \"MECC\", \n",
    "    \"Munich\": \"MUNICH\", \n",
    "    \"Rainbow\": \"NLCS\", \n",
    "    \"Quasar\": \"QUASAR\", \n",
    "    \"TCGA\": \"TCGA\", \n",
    "    \"Yorkshire-resections\": \"YCR-BCIP\"\n",
    "}\n",
    "res_revers = dict((v, k) for k, v in res.items())\n",
    "bio = {\"Yorkshire-biopsies\": \"YCR-BCIP-biopsies\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772dda8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, columns, img_size = 2, 5, 3\n",
    "plt.figure(figsize=(columns * img_size, rows * img_size))\n",
    "for i, cohort in enumerate(res_revers.keys()):\n",
    "    num_tiles = np.array(cohort_dict[res_revers[cohort]])\n",
    "\n",
    "    plt.subplot(rows, columns, i + 1)\n",
    "    if cohort == \"MUNICH\":\n",
    "        plt.yticks(range(0, 21, 5))\n",
    "    plt.hist(num_tiles, bins=50)\n",
    "    plt.axvline(x=num_tiles.mean(), color='tab:orange', label=int(num_tiles.mean().round()))\n",
    "    plt.xlim([-300, 12500])\n",
    "    plt.xlabel('Number of tiles')\n",
    "    plt.ylabel('Number of slides')\n",
    "    plt.title(cohort)\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_path / f'num_tiles_resections.svg',  format='svg', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935cc562",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, columns, img_size = 1, 1, 3\n",
    "plt.figure(figsize=(columns * img_size, rows * img_size))\n",
    "for i, cohort in enumerate(bio.keys()):\n",
    "    num_tiles = np.array(cohort_dict[cohort])\n",
    "\n",
    "    plt.subplot(rows, columns, i + 1)\n",
    "    plt.hist(num_tiles, bins=50)\n",
    "    plt.axvline(x=num_tiles.mean(), color='tab:orange', label=int(num_tiles.mean().round()))\n",
    "\n",
    "#     plt.xlim([-300, 12500])\n",
    "    plt.xlabel('Number of tiles')\n",
    "    plt.ylabel('Number of slides')\n",
    "    plt.title(bio[cohort])\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_path / f'num_tiles_biopsies.svg',  format='svg', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574601ad",
   "metadata": {},
   "source": [
    "## Age distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a9f8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohorts = [\"Belfast\", \"CPTAC\", \"Dachs\", \"Duessel\", \"MECC\", \"Munich\", \"Quasar\", \"Rainbow\", \"TCGA\", \"Yorkshire-biopsies\", \"Yorkshire-resections\"]\n",
    "target = 'isMSIH'\n",
    "categories = ['Not mut.', 'Mutat.', 'nonMSIH', 'MSIH', 'WT', 'MUT', 'wt', 'MT']\n",
    "norm = \"macenko\"\n",
    "feats = \"ctranspath\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916cf823",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_dict = {}\n",
    "for cohort in cohorts:\n",
    "    num_tiles = []\n",
    "\n",
    "    clini_table = MSI_cohorts_munich[cohort]['clini_table']\n",
    "    slide_csv = MSI_cohorts_munich[cohort]['slide_csv']\n",
    "    feature_dir = MSI_cohorts_munich[cohort]['feature_dir'][norm][feats]\n",
    "\n",
    "    clini_df = pd.read_csv(clini_table, dtype=str) if Path(clini_table).suffix == '.csv' else pd.read_excel(\n",
    "        clini_table, dtype=str)\n",
    "    print(cohort, clini_df.keys())\n",
    "    \n",
    "    slide_df = pd.read_csv(slide_csv, dtype=str)\n",
    "    df = clini_df.merge(slide_df, on='PATIENT')\n",
    "    # adapt dataframe to case sensitive clini tables\n",
    "    df = df.rename({\n",
    "        'MSI': 'isMSIH',\n",
    "        'BRAF': 'braf', 'BRAF_mutation': 'braf', 'braf_status': 'braf', \n",
    "        'KRAS': 'kras', 'kras_status': 'kras', 'KRAS_mutation': 'kras',\n",
    "        'NRAS': 'nras', 'NRAS_mutation': 'nras',  \n",
    "        'Age': 'AGE',\n",
    "    }, axis=1)\n",
    "    if 'AGE' not in df.keys():\n",
    "        continue\n",
    "        \n",
    "    # remove columns not in target_labels\n",
    "    for key in df.columns:\n",
    "        keys = [target] + ['PATIENT', 'SLIDE', 'FILENAME', 'AGE']\n",
    "        if key not in keys:\n",
    "            df.drop(key, axis=1, inplace=True)\n",
    "    # remove rows/slides with non-valid labels\n",
    "    df = df[df[target].isin(categories)]\n",
    "    # remove slides we don't have\n",
    "    h5s = set(feature_dir.glob('*.h5'))\n",
    "    assert h5s, f'no features found in {feature_dir}!'\n",
    "    h5_df = pd.DataFrame(h5s, columns=['slide_path'])\n",
    "    # h5_df['FILENAME'] = h5_df.slide_path.map(lambda p: p.stem.split('.')[0])\n",
    "    h5_df['FILENAME'] = h5_df.slide_path.map(lambda p: p.stem.split('.')[0]) if cohort=='TCGA' else h5_df.slide_path.map(lambda p: p.stem)\n",
    "    df = df.merge(h5_df, on='FILENAME')\n",
    "\n",
    "    # reduce to one row per patient with list of slides in `df['slide_path']`\n",
    "    patient_df = df.groupby('PATIENT').first().drop(columns='slide_path')\n",
    "    patient_slides = df.groupby('PATIENT').slide_path.apply(list)\n",
    "    df = patient_df.merge(patient_slides, left_on='PATIENT', right_index=True).reset_index()\n",
    "\n",
    "    assert len(df[target].unique()) == 2\n",
    "\n",
    "    df = df.dropna(axis=0, subset='AGE')\n",
    "    df['AGE'] = df['AGE'].astype(int)\n",
    "    \n",
    "    cohort_dict[cohort] = np.array(df['AGE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb19c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cohort in cohorts:\n",
    "    if cohort not in cohort_dict.keys():\n",
    "        continue\n",
    "    num_tiles = np.array(cohort_dict[cohort])\n",
    "    print(cohort, num_tiles.mean().round(), num_tiles.min(), num_tiles.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0cde8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {\n",
    "    \"CPTAC\": \"CPTAC\", \n",
    "    \"Dachs\" : \"DACHS\", \n",
    "#     \"Duessel\": \"DUSSEL\", \n",
    "#     \"Belfast\": \"Epi700\", \n",
    "#     \"MECC\": \"MECC\", \n",
    "#     \"Munich\": \"MUNICH\", \n",
    "    \"Rainbow\": \"NLCS\", \n",
    "    \"Quasar\": \"QUASAR\", \n",
    "    \"TCGA\": \"TCGA\", \n",
    "    \"Yorkshire-resections\": \"YCR-BCIP\"\n",
    "}\n",
    "res_revers = dict((v, k) for k, v in res.items())\n",
    "bio = {\"Yorkshire-biopsies\": \"YCR-BCIP-biopsies\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0518cf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, columns, img_size = 2, 5, 3\n",
    "plt.figure(figsize=(columns * img_size, rows * img_size))\n",
    "for i, cohort in enumerate(res_revers.keys()):\n",
    "    print(cohort, res_revers[cohort], res.keys())\n",
    "    if cohort not in res_revers.keys():\n",
    "        continue    \n",
    "    num_tiles = np.array(cohort_dict[res_revers[cohort]])\n",
    "    plt.subplot(rows, columns, i + 1)\n",
    "#     if cohort == \"MUNICH\":\n",
    "#         plt.yticks(range(0, 21, 5))\n",
    "    plt.hist(num_tiles, bins=num_tiles.max()-num_tiles.min())\n",
    "    plt.axvline(x=num_tiles.mean(), color='tab:orange', label=int(num_tiles.mean().round()))\n",
    "    plt.xlim([0, 100])\n",
    "    plt.xlabel('Number of tiles')\n",
    "    plt.ylabel('Number of slides')\n",
    "    plt.title(cohort)\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_path / f'num_tiles_resections.svg',  format='svg', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb6a055",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, columns, img_size = 1, 1, 3\n",
    "plt.figure(figsize=(columns * img_size, rows * img_size))\n",
    "for i, cohort in enumerate(bio.keys()):\n",
    "    num_tiles = np.array(cohort_dict[cohort])\n",
    "\n",
    "    plt.subplot(rows, columns, i + 1)\n",
    "    plt.hist(num_tiles, bins=num_tiles.max()-num_tiles.min())\n",
    "    plt.axvline(x=num_tiles.mean(), color='tab:orange', label=int(num_tiles.mean().round()))\n",
    "\n",
    "    plt.xlim([0, 100])\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Number of patients')\n",
    "    plt.title(bio[cohort])\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_path / f'num_tiles_biopsies.svg',  format='svg', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35f23bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a681d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_revers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b69a7a",
   "metadata": {},
   "source": [
    "### find out missing stats about cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f2ceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = \"CPTAC\"\n",
    "target = 'isMSIH'\n",
    "categories = ['Not mut.', 'Mutat.', 'nonMSIH', 'MSIH', 'WT', 'MUT', 'wt', 'MT']\n",
    "norm = \"macenko\"\n",
    "feats = \"ctranspath\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c108c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clini_table = MSI_cohorts_munich[cohort]['clini_table']\n",
    "slide_csv = MSI_cohorts_munich[cohort]['slide_csv']\n",
    "feature_dir = MSI_cohorts_munich[cohort]['feature_dir'][norm][feats]\n",
    "\n",
    "clini_df = pd.read_csv(clini_table, dtype=str) if Path(clini_table).suffix == '.csv' else pd.read_excel(\n",
    "    clini_table, dtype=str)\n",
    "slide_df = pd.read_csv(slide_csv, dtype=str)\n",
    "df = clini_df.merge(slide_df, on='PATIENT')\n",
    "# adapt dataframe to case sensitive clini tables\n",
    "df = df.rename({\n",
    "    'MSI': 'isMSIH',\n",
    "    'BRAF': 'braf', 'BRAF_mutation': 'braf', 'braf_status': 'braf', \n",
    "    'KRAS': 'kras', 'kras_status': 'kras', 'KRAS_mutation': 'kras',\n",
    "    'NRAS': 'nras', 'NRAS_mutation': 'nras',  \n",
    "    'Age': 'AGE',\n",
    "}, axis=1)\n",
    "\n",
    "# remove columns not in target_labels\n",
    "for key in df.columns:\n",
    "    keys = [target] + ['PATIENT', 'SLIDE', 'FILENAME', 'AGE', 'Cancer Type'] if target != '' else ['PATIENT', 'SLIDE', 'FILENAME']\n",
    "    if key not in keys:\n",
    "        df.drop(key, axis=1, inplace=True)\n",
    "# remove rows/slides with non-valid labels\n",
    "df = df[df[target].isin(categories)]\n",
    "# remove slides we don't have\n",
    "h5s = set(feature_dir.glob('*.h5'))\n",
    "assert h5s, f'no features found in {feature_dir}!'\n",
    "h5_df = pd.DataFrame(h5s, columns=['slide_path'])\n",
    "# h5_df['FILENAME'] = h5_df.slide_path.map(lambda p: p.stem.split('.')[0])\n",
    "h5_df['FILENAME'] = h5_df.slide_path.map(lambda p: p.stem.split('.')[0]) if cohort=='TCGA' else h5_df.slide_path.map(lambda p: p.stem)\n",
    "df = df.merge(h5_df, on='FILENAME')\n",
    "\n",
    "# reduce to one row per patient with list of slides in `df['slide_path']`\n",
    "patient_df = df.groupby('PATIENT').first().drop(columns='slide_path')\n",
    "patient_slides = df.groupby('PATIENT').slide_path.apply(list)\n",
    "df = patient_df.merge(patient_slides, left_on='PATIENT', right_index=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60247c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age\n",
    "# df = df.dropna(axis=0, subset='AGE')\n",
    "# df['AGE'] = df['AGE'].astype(int)\n",
    "# print(df['AGE'].mean(), df['AGE'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec64144",
   "metadata": {},
   "outputs": [],
   "source": [
    "clini_df.keys().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386c73e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clini_df[clini_df[\"Cancer Type\"] == \"Colorectal Cancer\"]\n",
    "# clini_df[clini_df[\"Sex\"] == \"Male\"]\n",
    "# clini_df[clini_df[\"Cancer Stage\"] == 'Stage IV']\n",
    "clini_df[clini_df[\"Tumor Site\"] == 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a0126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clini_df[\"Tumor Site\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5327d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate some fake data to plot\n",
    "data = np.random.rand(10, 10)\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(data, cmap='RdBu_r')\n",
    "\n",
    "# Add the colorbar\n",
    "cbar = plt.colorbar(im, ticks=[0.0, 0.5, 1.])\n",
    "cbar.ax.set_yticklabels(['low', 'medium', 'high'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb11287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import numpy as np\n",
    "\n",
    "ax = plt.subplot()\n",
    "im = ax.imshow(np.arange(100).reshape((10, 10)))\n",
    "\n",
    "# create an Axes on the right side of ax. The width of cax will be 5%\n",
    "# of ax and the padding between cax and ax will be fixed at 0.05 inch.\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "plt.colorbar(im, cax=cax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a432bb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 0.4))\n",
    "fig.subplots_adjust(bottom=0.5)\n",
    "\n",
    "cmap = mpl.cm.RdBu_r\n",
    "norm = mpl.colors.Normalize(vmin=0, vmax=1)\n",
    "\n",
    "cb1 = mpl.colorbar.ColorbarBase(ax, cmap=cmap,\n",
    "                                norm=norm,\n",
    "                                orientation='horizontal', ticks=[0, 1.])\n",
    "cb1.ax.set_xticklabels(['low', 'high'])\n",
    "\n",
    "plt.savefig(output_path / f'colorbar_attention.svg',  format='svg', bbox_inches = 'tight', pad_inches = 0)\n",
    "# cb1.set_label('Attention')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19638ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 0.4))\n",
    "fig.subplots_adjust(bottom=0.5)\n",
    "\n",
    "cmap = mpl.cm.viridis\n",
    "norm = mpl.colors.Normalize(vmin=0, vmax=1)\n",
    "\n",
    "cb1 = mpl.colorbar.ColorbarBase(ax, cmap=cmap,\n",
    "                                norm=norm,\n",
    "                                orientation='horizontal', ticks=[0, 1.])\n",
    "# cb1.ax.set_yticklabels(['low', 'high'])\n",
    "\n",
    "plt.savefig(output_path / f'colorbar_classification.svg',  format='svg', bbox_inches = 'tight', pad_inches = 0)\n",
    "# cb1.set_label('Some Units')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578d306d",
   "metadata": {},
   "source": [
    "# Analysis of clinicopathologicla features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff40c2bc",
   "metadata": {},
   "source": [
    "## Plot AUROCs for subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b617690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path('/home/haicu/sophia.wagner/projects/idkidc/figures') \n",
    "\n",
    "test_cohorts = 'YCR-BCIP-resections'\n",
    "cohort = 'YCR-BCIP-resections'\n",
    "cohort_label = 'YCR-BCIP'\n",
    "\n",
    "cfg.norm = norm = 'histaugan'\n",
    "cfg.feats = feats =  'ctranspath'\n",
    "cfg.target = 'isMSIH'\n",
    "categories = ['Not mut.', 'Mutat.', 'nonMSIH', 'MSIH', 'WT', 'MUT', 'wt', 'MT']\n",
    "target_labels = [cfg.target]\n",
    "true_label = 1.\n",
    "clini_info = {'AGE': None, 'GENDER': None, 'LEFT_RIGHT': None, 'STAGE': None}\n",
    "\n",
    "label_dict = {\n",
    "    'Not mut.': 0,\n",
    "    'Mutat.': 1,\n",
    "    'nonMSIH': 0,\n",
    "    'MSIH': 1,\n",
    "    'WT': 0,\n",
    "    'MUT': 1,\n",
    "    'wt': 0,\n",
    "    'MT': 1,\n",
    "    'left': 1,\n",
    "    'right': 0,\n",
    "    'female': 1,\n",
    "    'male': 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790b953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_paths = result_path.glob(f'fold*/outputs_{test_cohorts}.csv')\n",
    "pred_csvs = list(csv_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899d1060",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = Path('data_config.yaml')\n",
    "with open(data_config, 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "\n",
    "    clini_table = Path(data_config[cohort]['clini_table'])\n",
    "    slide_csv = Path(data_config[cohort]['slide_csv'])\n",
    "    feature_dir = Path(data_config[cohort]['feature_dir'][norm][feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391de8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import get_cohort_df\n",
    "\n",
    "df = get_cohort_df(clini_table, slide_csv, feature_dir, [cfg.target], categories, cohort, clini_info) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e9becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LEFT_RIGHT'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e758610",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GENDER'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e82e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['AGE'].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45def5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['STAGE'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a10165",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AGE'] = df['AGE'].astype(int)\n",
    "df['STAGE'] = pd.to_numeric(df['STAGE'], errors='coerce', downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d62b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# state the condition\n",
    "# --------------------------\n",
    "\n",
    "# age\n",
    "# lower = 0\n",
    "# upper = 60\n",
    "# df = df[df['AGE'] < upper]\n",
    "# df = df[df['AGE'] >= lower]\n",
    "\n",
    "# gender\n",
    "gender = 'female'\n",
    "df = df[df['GENDER'] == gender]\n",
    "\n",
    "# # tumor site\n",
    "# site = 'left'\n",
    "# df = df[df['LEFT_RIGHT'] == site]\n",
    "\n",
    "# stage\n",
    "stage = 3\n",
    "df = df[df['STAGE'] == stage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58437580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.read_csv(pred_csvs[0], dtype=str).rename({'patient': 'PATIENT'}, axis=1)\n",
    "# logits = test_df['logits'].astype(float)\n",
    "# test_df['predictions'] = torch.tensor(logits.values).sigmoid().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c676454",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dfs = [pd.read_csv(p, dtype=str).rename({'patient': 'PATIENT'}, axis=1) for p in pred_csvs]\n",
    "pred_dfs = [pd.merge(pred_dfs[i], df, on=\"PATIENT\", how='inner', ) for i in range(len(pred_dfs))]\n",
    "\n",
    "y_trues = [df[\"ground_truth\"] == f'{true_label:.1f}' for df in pred_dfs]\n",
    "# y_trues = [label_dict[df[cfg.target]] == 'ground_truth' for df in pred_dfs]\n",
    "y_preds = [pd.to_numeric(df[f'logits']) for df in pred_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a9bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "for i in range(len(y_trues)):\n",
    "    fpr, tpr, _ = roc_curve(y_trues[i], y_preds[i])\n",
    "    roc_auc = roc_auc_score(y_trues[i], y_preds[i])\n",
    "    \n",
    "#     ax.plot(fpr, tpr, label=f'AUC = {roc_auc:0.2f}', alpha=0.3, color='black')\n",
    "\n",
    "\n",
    "    interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(roc_auc)\n",
    "ax.plot([0, 1], [0, 1], linestyle=\"--\", lw=1, color=\"gray\", label=\"Chance\", alpha=0.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "# plot mean curve\n",
    "ax.plot(\n",
    "    mean_fpr,\n",
    "    mean_tpr,\n",
    "    color=\"black\",\n",
    "    label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.3f)\" % (mean_auc, std_auc),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(\n",
    "    mean_fpr,\n",
    "    tprs_lower,\n",
    "    tprs_upper,\n",
    "    color=\"grey\",\n",
    "    alpha=0.5,\n",
    "    label=r\"$\\pm$ 1 std. dev.\",\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05],\n",
    "    # title=f\"ROC for patients with: {lower} ≤ age < {upper} (n={len(df)})\",\n",
    "    # title=f\"ROC for patients with: gender = {gender} (n={len(df)})\",\n",
    "    # title=f\"ROC for patients with: tumor position = {site} (n={len(df)})\",\n",
    "    title=f\"ROC for patients with: stage = III (n={len(df)})\",\n",
    ")\n",
    "\n",
    "ax.set_xlabel('1 - Specificity')\n",
    "ax.set_ylabel('Sensitivity')\n",
    "\n",
    "ax.legend(loc=\"lower right\")\n",
    "# fig.savefig(output_path / f'auroc_{test_cohorts}_{cfg.target}_age_{lower}_{upper}.svg', format='svg', bbox_inches = 'tight', pad_inches = 0)\n",
    "# fig.savefig(output_path / f'auroc_{test_cohorts}_{cfg.target}_gender_{gender}.svg', format='svg', bbox_inches = 'tight', pad_inches = 0)\n",
    "# fig.savefig(output_path / f'auroc_{test_cohorts}_{cfg.target}_site_{site}.svg', format='svg', bbox_inches = 'tight', pad_inches = 0)\n",
    "# fig.savefig(output_path / f'auroc_{test_cohorts}_{cfg.target}_stage_{stage}.svg', format='svg', bbox_inches = 'tight', pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0282813d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f1af58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fe9aff0ab47136056049936c4658da4ba2cd99c7d1ecd6f48215068e2b5bffd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
