# logging options
save_dir:
  desc: path to save models, outputs, and folds
  # value: /home/ubuntu/logs
  value: /lustre/groups/peng/workspace/sophia.wagner/logs/idkidc
project:
  desc: wandb project name
  value: hackathon
name:
  desc: costum prefix for logging
  value: debug

# task definition
data_config:
  desc: config file for data paths
  # value: /home/ubuntu/projects/idkidc/data_config.yaml
  value: /home/haicu/sophia.wagner/projects/idkidc/data_config.yaml
task:
  desc: training task in ['binary', 'multiclass', 'multilabel']
  value: multiclass
target:
  desc: targets used for training
  value: isMSIH
num_classes:
  desc: number of classes for training
  value: 4
cohorts:
  desc: cohort used for training, in the shape ["cohort_name_1", "cohort_name_2"]
  value: ["MCO"]
ext_cohorts:
  desc: cohort used for external validation
  # value: ["MCO", "DACHS", "QUASAR", "RAINBOW", "TCGA", "Epi700"]
  value: ["MCO", "DACHS", "QUASAR", "RAINBOW", "TCGA", "Epi700", "CPTAC", "DUSSEL", "MECC", "MUNICH", "YCR-BCIP-resections", "YCR-BCIP-biopsies", "FOXTROT", "MAINZ"]
clini_info:
  desc: dict with stats for clinical labels to include in training. not used if value = {} (empty dictionary)
  value: {}
    # AGE:
    #   mean: null
    #   std: null
    # GENDER:
    #   mean: null
    #   std: null
    # LEFT_RIGHT:
    #   mean: null
    #   std: null
seed:
  desc: random state, e.g., for splitting the data
  value: null
label_dict:
  desc: dictionary to map labels to numeric values
  value:
    Not mut.: 0
    Mutat.: 1
    nonMSIH: 0
    MSIH: 1
    WT: 0
    MUT: 1
    wt: 0
    MT: 1
    left: 1
    right: 0
    female: 1
    male: 0
    Stage I: 0
    Stage II: 1
    Stage III: 2
    Stage IV: 3


# model options
model:
  desc: costum prefix for logging
  value: transformer
norm:
  desc: type of pre-processing
  value: macenko
feats:
  desc: type of features
  value: ctranspath
input_dim:
  desc: num of output channels of the features extractor
  value: 768
num_tiles:
  desc: number of tiles to sample from all tiles
  value: -1
pad_tiles:
  desc: whether to pad the tiles up to num_tiles if number of tiles is smaller than num_tiles
  value: false

# training options
folds:
  desc: number of folds
  value: 5
num_epochs:
  desc: number of epochs
  value: 1
criterion: 
  desc: loss function for model training
  value: BCEWithLogitsLoss
optimizer:
  desc: optimizer for model training
  value: AdamW
criterion: 
  desc: loss function for model training
  value: CrossEntropyLoss  # BCEWithLogitsLoss
scheduler:
  desc: scheduler for model training
  value: null
lr:
  desc: learning rate
  value: 2.0e-05
wd:
  desc: weight decay
  value: 2.0e-05
bs:
  desc: batch size during training
  value: 1
stop_criterion:
  desc: metric for choosing best model
  value: loss
val_check_interval:
  desc: interval to evaluate on validation set
  value: 500
resume:
  desc: path to trained model for evaluation
  value: null
debug:
  desc: debug flag, turns off login etc.
  value: false
num_samples:
  desc: for experiment to analyze number of samples
  value: null
  