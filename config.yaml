# logging options
save_dir:
  desc: path to save models, outputs, and folds
  value: /home/ubuntu/logs
project:
  desc: wandb project name
  value: hackathon
name:
  desc: costum prefix for logging
  value: test

# task definition
task:
  desc: training task in ['binary', 'multiclass', 'multilabel']
  value: binary
target:
  desc: targets used for training
  value: isMSIH
num_classes:
  desc: number of classes for training
  value: 1
cohorts:
  desc: cohort used for training
  value: ["TCGA"]
ext_cohorts:
  desc: cohort used for external validation
  value: ["CPTAC"]
clini_info:
  desc: whether to use clinical information during training
  value: false
seed:
  desc: random state for splitting the data
  value: null

# model options
model:
  desc: costum prefix for logging
  value: transformer
norm:
  desc: type of pre-processing
  value: macenko
feats:
  desc: type of features
  value: ctranspath
input_dim:
  desc: num of output channels of the features extractor
  value: 768
num_tiles:
  desc: number of tiles to sample from all tiles
  value: -1
pad_tiles:
  desc: whether to pad the tiles up to num_tiles if #tiles is smaller than num_tiles
  value: false

# training options
folds:
  desc: number of folds
  value: 5
num_epochs:
  desc: number of epochs
  value: 1
optimizer:
  desc: optimizer for model training
  value: AdamW
scheduler:
  desc: scheduler for model training
  value: null
lr:
  desc: learning rate
  value: 2.0e-05
wd:
  desc: weight decay
  value: 2.0e-05
bs:
  desc: batch size during training
  value: 1
stop_criterion:
  desc: metric for choosing best model
  value: loss
resume:
  desc: path to trained model for evaluation
  value: null
debug:
  desc: debug flag, turns off login etc.
  value: false
